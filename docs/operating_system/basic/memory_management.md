# 内存管理

计算机系统的主要目的是执行程序。在执行时，这些程序机器访问数据应该至少部分在内存里。

为了提高CPU的利用率和响应用户的速度，通用计算机在内存里必须保留多个进程。内存管理方案有很多，采用的方法也不同；每个算法的有效性取决于特定的情况。系统内存管理方案的选择取决于很多因素，特别是系统的硬件设计。大多数算法都需要硬件支持。

## 内存管理策略

一组进程可以共享一个CPU。正是由于CPU调度，提高了CPU的利用率和计算机响应用户的速度。然而，为了实现性能的改进，应将多个程序保存在内存中；也就是说，必须共享内存。

这一部分讨论内存的各种管理方法。内存管理算法有很多：从原始的裸机方法，到分页和分段的方法。每种方法都有各自的优点和缺点。为特定系统选择内存管理方法取决于很多因素，特别是系统的硬件设计。正如将会看到，许多算法都需要硬件支持，导致许多操作系统内存管理和硬件的紧密结合。

### 背景

内存是现代操作系统的核心。内存由一个很大的字节数组组成，每个字节都有各自的地址。CPU根据程序计数器的值从内存中提取指令，这些指令可能引起对特定内存地址的额外加载与存储。

例如，一个典型的指令执行周期，首先从内存读取指令。接着，该指令会被解码，也可能需要从内存中读取操作数。在指令对操作数执行后，它的结果可能存回到内存。内存单元只看到地址流，而并不知道这些地址是如何产生的（由指令计数器、索引、间接寻址、常亮地址等）或它们是什么（指令或数据）的地址。相应地，我们可以忽略内存地址是如何由程序产生的，而只是对运行程序产生的的内存地址序列感兴趣。

#### 基本硬件

CPU内置寄存器通常可以在一个CPU时钟周期内完成访问。但内存访问可能需要多个CPU时钟周期。这种情况下，由于没有数据以便完成正在执行的指令，CPU通常需要 **暂停**（stall）。补救措施是在CPU与内存之间——通常是在CPU芯片上——增加 **高速缓存**（cache）。为管理CPU内置的缓存，硬件加快内存访问，无需任何操作系统的控制。

出于保护，需要保证每个进程有单独的地址空间，**基地址寄存器**（base register）含有最小的合法的物理内存地址。**界地址寄存器**（limit register）指定了范围的大小。如下如所示：

<center>![BaseLimit](./images/base_limit.png)</center>
<center>基地址寄存器和接线地址寄存器定义逻辑地址空间</center>

内存空间保护的实现是通过CPU硬件对在用户模式下产生的地址与寄存器的地址进行比较来完成的。当在用户模式下执行的程序试图访问操作系统内存或其他用户内存时，会陷入操作系统，而操作系统则将其作为致命错误来处理，如下如所示。这种方案防止用户程序无意或故意修改操作系统或其他用户的代码或数据结构。

<center>![HWAddressProtect](./images/hw_address_protect.png)</center>
<center>采用基地址寄存器和接线地址寄存器的硬件地址保护</center>

在内核模式下执行的操作系统可以无限制地访问操作系统及用户的内存。这项规定允许操作系统：加载用户程序到用户内存，转储出现错误的程序，访问和修改操作系统调用的参数，执行用户内存的I/O，以及提供许多其他服务等。例如，多任务系统的操作系统在进行上下文切换时，应将一个进程的寄存器的状态存贷内存，再从内存中调入下个进程的上下文到寄存器。

#### 地址绑定

在磁盘上等待调到内存以便执行的进程形成 **输入队列**（input queue）。

用户程序在执行前一般会经过若干步骤，如下图所示：

<center>![StepOfUserProgram](./images/step_of_user_program.png)</center>
<center>一个用户程序的多步骤处理</center>

通常，数据 **绑定**（bind）到存储器地址可在沿途的的任何一步进行：

* **编译时**（compile time）：如果在编译时就可以知道进程在内存中的驻留地址，那么就可以生成 **绝对代码**（absolute code）。  
例如，如果事先知道用户进程驻留在内存地址 $R$ 处，那么生成的编译代码就可以从该位置开始并向后延伸。如果将来开始地址发生变化，那么就必须重新编译代码。MS-DOS的.COM格式的程序就是在编译时绑定成绝对代码的。
* **加载时**（load time）：如果在编译时并不知道进程将驻留在何处，那么编译器就应该生成 **可重定位代码**（relocatable code）。对这种情况，最后绑定会延迟到加载时才进行。如果开始地址发生变化，那么只需要重新加载用户代码已合并更改的值。
* **执行时**（runtime time）如果进程在执行时可以从一个内存段移到另一个内存段，那么绑定应延迟到执行时才进行。如下节所属，采用这种方案需要特定硬件支持。大多数的通用计算机操作系统采用这种方法。

#### 逻辑地址空间和物理地址空间

CPU生成的地址通常称为 **逻辑地址**（logical address），而内存单元看到的地址（即加载到 **内存地址寄存器**（memory-address register）的地址）通常称为 **物理地址**（physical address）。

编译时和加载时的地址绑定方法生成相同的逻辑地址和物理地址。然而，执行时的地址绑定方案生成不同的逻辑地址和物理地址。在这种情况下，通常称逻辑地址为 **虚拟地址**（virtual address）。在 **基础梳理** 部分我们对 *逻辑地址* 和 *虚拟地址* 不加区分。有程序生成的逻辑地址集合称为 **逻辑地址空间**（logical address space），这些逻辑地址对应的所有物理地址集合称为 **物理地址空间**（physical address space）。

从虚拟地址到物理地址的运行时映射是由 **内存管理单元**（Memory-Management Unit，MMU）的硬件设备来完成。有多种方案来完成这种映射，这里以一个简单的实现方案为例（也是前述基地址寄存器方案的推广）。基地址寄存器这里称为 **重定位寄存器**（relocation register）。

<center>![DynamicRelocate](./images/dynamic_relocate.png)</center>
<center>使用重定位寄存器的动态重定位</center>

#### 动态加载

如果一个进程的所有数据都在物理内存中，则进程的大小将受限于内存的大小。为了获得更好的内存空间利用率，可以使用 **动态加载**（dynamic loading）。

#### 动态链接与共享库

**动态链接库**（dynamically linked library）为系统库，可链接到用户程序，以便运行。有的操作系统只支持 **静态链接**（static linking），它的系统库与其他目标模块一样，通过加载程需，被合并到二进制程序映像。动态链接类似于动态加载。这里，不是加载而是连接，会延迟到运行时。这种功能通常用于系统库，如语言的子程序库。没有这种功能，系统内的所有程序都需要一份语言库的副本（或至少那些被程序所引用的子程序）。这种要求浪费了磁盘空间和内存空间。

如果有动态链接，在二进制映像内，每个库程序的引用都有一个 **存根**（stub）。存根是一小段代码，用来指出如何定位适当的内存驻留库程序，或者在程序不在内存时应如何加载库。

动态链接也可以用于库的更新（如修改bug）。版本信息包含在程序和库中。一个哭的多个版本都可以加载到内存，程序将通过版本信息确定使用哪个库的副本。次要更改保留相同的版本号，而主要更改则增加版本号。因此，只有采用新库编译的程序才会受新库的不兼容改动的影响。在新库安装之前链接的其他程序将继续使用较旧的库。这种系统也称为 **共享库**（shared library）。

与动态加载不同，动态链接通常需要操作系统的帮助。如果内存中的进程是彼此保护的，那么只有操作系统才可以检查所需程序是否在某个进程的内存空间内，或是允许多个进程访问同样的内存地址。这个概念将在 **分页** 部分被更详细地讨论。

### 交换

进程必须在内存中以便执行。不过，进程可以暂时从内存 **交换**（swap）到 **备份存储**（backing store），当再次执行时在调回到内存中，如下图：

<center>![Swap](./images/swap.png)</center>
<center>使用磁盘作为存储仓库的两个进程的交换</center>

交换有可能让所有进程的总的物理地址空间超过真实系统的物理地址空间，从而增加了系统的多道程序程度。

#### 标准交换

标准交换在内存和备份存储之间移动进程。系统维护一个可运行的所有进程的 **就绪队列**（ready queue），它们的映像在备份存储或内存中。当CPU决定要执行一个进程时，他调用分派器。分配器检查队列中的下一个进程是否在内存中。如果不在，并且没有空闲内存区域，那么分派器会换出（swap out）当前位于内存中的一个进程，并换入（swap in）所需进程。然后重新加载寄存器，并将控制权转移到所选进程。

这种交换系统的上下文切换时间相当高。因此知道一个进程真正需要的内存空间而不是可能需要的内存空间是非常有用的。用户需要告诉系统它的内存需求情况。因此，具有动态内存需求的进程需要通过系统调用（`request_memory()`和`release_memory()`）来通知操作系统它的内存需求变化情况。

考虑一种特殊情况，我们需要换出进程 $P_1$ 而换入进程 $P_2$，显然 $P_1$ 应处于空闲状态。然而如果如果I/O异步访问用户内存的I/O缓冲区，那么该进程就不能换出。I/O操作可能试图使用现在已属于进程 $P_2$ 的内存。解决这个问题有两种主要方法：

* 不能换出等待处理I/O的进程；
* I/O操作的执行只能使用操作系统的缓冲。

第二种方法只有在进程换入时，操作系统缓冲与进程内存之间才能进行数据转移。这种 **双缓冲**（double buffering）本身增加了开销。我们现在需要再次复制数据，从内核内存到用户内存，然后用户进程可以访问它。

现代操作系统并不适用标准交换，而是使用一些常见变种：

* 正常情况下，禁止交换；当空闲内存（未被操作系统或进程使用的内存）低于某个阈值时，启用交换。当空闲内存数量增加了，就停止交换。
* 交换进程的部分（而不是整个进程），以降低交换时间。

通常这些交换的变种与虚拟内存一起工作。

#### 移动系统的交换

移动系统通常不支持任何形式的交换。移动设备通常采用闪存，导致的空间约束是移动操作系统设计者避免交换的原因之一。另外其他的原因：

* 闪存写入次数的限制
* 内存闪存之间吞吐量的差异


### 连续内存分配

内存通常分为两个区域：一个用于 *驻留操作系统*，另一个用于 *用户进程*。操作系统可以放在低内存或高内存。影响这一决定的主要因素是中断向量的位置。由于中断向量通常位于低内存。因此工程师一般将操作系统也放在低内存。

需要考虑，如何将输入队列中需要调入内存的进程分配内存空间。在采用 **连续内存分配**（contiguous memory allocation）时，每个进程位于一个连续的内存区域，与包含下一进城的内存相连。

#### 内存保护

前面讨论过基于重定位寄存器和界限寄存器的内存地址保护机制。同时重定位方案提供了一种方式以便 *操作系统动态改变其大小*。这一灵活性用途广泛。例如，操作系统的驱动程序需要代码和缓冲空间。如果一个驱动程序（或其他操作系统的服务）不常使用，可以不必在内存中保留它的代码和数据，这部分空间可以用于其他目的。这类代码有时称为 **暂时**（transient）的操作系统代码；它们根据需要调入调出。

#### 内存分配

最简单的分配方法之一，就是将内存分为多个固定大小的 **分区**（partition）。每个分区可以只包含一个进程。因此，多道程序的程序受限于分区数。如果使用这种 **多分区方法**（multiple-partition method），那么当一个分区空闲时，它的分区可以用于其他进程。

对于 **可变分区**（variable-partition）方案，操作系统有一个表，用于记录哪些内存可用和哪些内存已用。开始，所有内存都可用于用户进程，因此可以作为一大块的可用内存，称为 **孔**（hole）。最终，内存是一个包括各种大小的孔的集合。

这种方法是通过 **动态存储分配问题**（dynamic storage-allocation problem）（根据一组空闲孔来分配大小为 $n$ 的请求）的一个特例。这个问题有许多解决方案。从一组可用孔中选择一个空闲孔的最为常用的方法包括：

* **首次适应**（first-fit）：分配首个足够大的孔。查找可以从头开始，也可以从上次首次适应结束时开始。一旦找到足够大的空闲孔，就可以停止。
* **最优适应**（best-fit）：分配最小的足够大的孔。应查找整个表，除非列表按大小排序。这种方法可以产生最小剩余孔。
* **最差适应**（worst-fit）：分配最大的孔。同样，应该查找整个列表，除非列表按大小排序。这种方法可以产生最大剩余孔，该孔可能比最优适应产生的较小剩余孔更为适用。

模拟结果显示，首次适应和最优适应在执行时间和利用空间方面都好于最差适应。首次适应和最优适应在利用空间方面难分伯仲，但是首次适应更快一些。

#### 碎片

内存分配的首次适应和最优适应算法都有 **外部碎片**（external fragmentation）的问题。采用首次适应方法的统计说明，不管使用什么优化，假定有 $N$ 个可分配块，那么可能有 $0.5N$ 个块为外部碎片。即 $\frac{1}{3}$ 的内存可能不能使用。这一特性称为 $50%规则$（50-percent rule）。

内存碎片也可以是外部的，也可以是内部的。假设有一个 $18464$ 字节大小的孔，并采用多分区分配方案。假设有一个进程需要 $18462$ 字节。如果只能分配所要求的块，那么还剩下一个 $2$ 个字节的孔。维护这个孔的开销要比孔本身大很多。因此，通常按固定大小的块为单位（而不是字节）来分配内存。采用这种方案，进程所分配的内存可能比所需要的要大。这两个数字只差称为 **内部碎片**（internal fragmentation），这部分内存在分区内部，但又不能用。

外部碎片问题的一种解决方案是 **紧缩**（compaction），它的目的是移动内存内容，以便将所有空闲空间合并成一整块。这种方法的开销昂贵。

外部碎片问题的另一个可能的解决方案是：允许进程的逻辑地址空间是不连续的；这样，只要有物理内存可用，就允许为进程分配内存。有两种互补的技术可以实现这个解决方案：分段和分页。这两个技术也可以组合起来。

碎片是一个常见的问题；当需要管理数据块时它就可能出现。在存储管理部分也会=有讨论。

### 分段

正如已经看到的，用户的内存视图和实际的物理内存不一样。这同样适用于程序员的内存视图。事实上，对操作系统和程序员来说，按物理性质来处理内存是不方便的。如果硬件可以提供内存机制，以便将程序员的内存视图映射到实际的物理内存，那么会如何？这样，系统将有更多的自由来管理内存，而程序员将有一个更自然的编程环境。分段提供了这种机制。

#### 基本方法

在大多数程序员眼中，内存不是一个字节的线性数组，有的包含指令而其他的包含数据。他们眼中的内存通常是一组不同长度的段，这些段之间并没有一定的顺序。

<center>![ProgramByProgrammer](./images/program_by_programmer.png)</center>
<center>程序员眼中的程序</center>

程序员眼中的程序是由主程序加上一组方法、过程或函数所构成的。它还可以包括各种数据结构：对象、数组、堆栈、变量等。每个模块或数据元素通过名称来引用。程序员会说“堆栈”、“数学库” 和 “主程序” 等，而并不关心这些元素所在内存的位置。她不关心堆栈式放在函数`Sqrt()`之前还是之后。这些段的长度是不同的，其长度是有这些段在程序中的目的决定的。段内的元素是通过它们距离段首的偏移来指定：程序的第一条语句、在堆栈里的第 $7$ 个栈帧、函数`Sqrt()`的第五条指令。

**分段**（segmentation）就是支持这种用户视图的内存管理方案。逻辑地址空间是由一组段构成。每个段都有名称和长度。地址指定了段名称和段内偏移。因此用户通过两个量来指定地址：段名称和段偏移。

为了实现简单起见，段是编号的，是通过短号而不是段名称来引用。因此，逻辑地址由有序对（two tuple）组成：

<center><段号，偏移></center>

通常，在编译用户程序时，编译器会根据输入程序来自动构造段。

一个 C 编译器可能会创建如下段：

* 代码
* 全局变量
* 堆（内存从堆上分配）
* 每个线程使用的栈
* 标准的 C 库

在编译时链接的库可能分配不同的段。加载程序会装入所有这些段，并为它们分配段号。

#### 分段硬件

虽然用户现在能通过二位地址来引用程序内的对象，但是实际物理内存仍然是一维的字节序列。因此，我们应定义一个实现方式，以便映射用户定义的二维地址到一维物理地址。这个地址是通过 **段表**（segment table）来实现的。段表的每个条目都有 **段基地址**（segment base）和 **段界限**（segment limit）。段基地址包含该段在内存中的开始物理地址，而段界限指定该段的长度。

<center>![HWForSegment](./images/hw_for_segment.png)</center>
<center>分段硬件</center>

段表的使用如上图所示。每个逻辑地址由两部分组成：段号 $s$ 和段偏移 $d$。段号用作段表的索引，逻辑地址的偏移 $d$ 应位于 $0$ 和段界限之间。如果不是这样，那么会陷入操作系统中（逻辑地址试图访问段的外面）。如果偏移 $d$ 合法，那么就与基址相加得到所需字节的物理内存地址。因此，段表实际上二元组 （*基址寄存器值*， *界限寄存器值*） 的数组。

<center>![SegmentationExample](./images/segmentation_example.png)</center>
<center>分段的例子</center>

如上图所示，前述例子中逻辑地址空间和物理内存之间通过段表映射。

### 分页

### 页表结构

### Intel 32位和64位体系结构

### ARM架构


## 虚存管理

上一部分讨论了计算机系统的各种内存管理策略。搜有这些策略都有共同的目标：同时将多个进程保存在内存中，以便允许多道程序。然而，这些策略都倾向于要求每个进程在执行之前应完全处于内存中。

虚拟内存技术允许执行进程不必完全处于内存。这种方案的一个主要优点是：程序可以大于物理内存。此外，虚拟内存将内存抽象成一个巨大的、统一的存储数组，进而实现了用户看到的逻辑内存与物理内存的分离。这种技术使得开发人员不再但担忧内存容量的限制。虚拟内存还允许进程轻松共享文件和实现内存共享。此外，它为创建进程提供了有效的机制。然而，虚拟内存的实现并不容易，并且使用不当还可能会大大降低性能。这一部分以请求调页为例讨论虚拟内存，并讨论其复杂性和开销。

### 背景

### 请求调页

### 写时复制

### 页面置换

### 帧分配

### 系统抖动

### 内存映射文件

### 分配内核内存

### 其他注意事项

### 操作系统例子

本节讨论 Windows 和 Solaris 如何实现虚拟内存。

#### Windows

#### Solaris
